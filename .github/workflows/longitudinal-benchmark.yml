# Longitudinal Benchmarks 
# 
# This workflow will run the benchmarks defined in the environment variable BENCHMARKS.
# It will collect and aggreate the benchmark output, format it and feed it to github-action-benchmark.
#
# The benchmark charts are live at https://intersectmbo.github.io/plutus/dev/bench
# The benchmark data is available at https://intersectmbo.github.io/plutus/dev/bench/data.js

name: ci

on:
  push:
    branches:
      - master

permissions:
  # Deployments permission to deploy GitHub pages website
  deployments: write
  # Contents permission to update benchmark contents in gh-pages branch
  contents: write

jobs:
  longitudinal-benchmark:
    name: "ðŸ©º Performance Regression Check"
    runs-on: [self-hosted, plutus-benchmark]
    steps:
      - name: Checkout 
        uses: actions/checkout@main 

      - name: Install Nix
        uses: DeterminateSystems/nix-installer-action@main

      - name: Run Benchmarks
        env: 
          BENCHMARKS: "validation validation-decode nofib marlowe"
        run: nix develop --command bash ./scripts/run-longitudinal-benchmarks.sh

      # We need this otherwise the next step will fail with:
      #   `pre-commit` not found.  Did you forget to activate your virtualenv?
      # This is because github-action-benchmark will call git commit outside nix develop.
      - name: Disable Git Hooks
        run: git config core.hooksPath no-hooks

      - name: Deploy Results
        uses: benchmark-action/github-action-benchmark@main
        with:
          name: Plutus Benchmarks
          tool: 'customSmallerIsBetter'
          output-file-path: output.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Push and deploy GitHub pages branch automatically
          auto-push: true
          # Enable alert commit comment
          comment-on-alert: true
          # Mention @IntersectMBO/plutus-core in the commit comment so that the 
          # team is notified via GitHub.
          alert-comment-cc-users: '@IntersectMBO/plutus-core'
          # It is a ratio indicating how worse the current benchmark result is. 
          # For example, if we now get 110 ns/iter and previously got 100 ns/iter, it got 10% worse.
          # We in this case we alert if it gets 5% worse.
          alert-threshold: '105%'
